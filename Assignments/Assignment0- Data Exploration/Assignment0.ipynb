{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 0: Data Exploration\n",
    "\n",
    "An important first step to every data analysis project is to explore your data. Data exploration helps you become familiar with your data, find noise and outliers, clean your data, and prepare your data for data mining. It is important that have a good understanding of what is in your data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Leaf Dataset\n",
    "\n",
    "For this task we'll be using a subset of the leaf dataset created by professors from University of Porto, Portugal. This dataset consists in a collection of shape and texture features extracted from digital images of leaf specimens originating from a total of 40 different plant species, but for the purpose of this assignment we're only going to consider 4 plant species.\n",
    "\n",
    "You can find more information about the dataset [here](http://archive.ics.uci.edu/ml/datasets/Leaf).\n",
    "\n",
    "<img src=\"imgs/screen4.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.25.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standard Headers\n",
    "# You are welcome to add additional headers here if you wish\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Enable inline mode for matplotlib so that Jupyter displays graphs\n",
    "%matplotlib inline\n",
    "\n",
    "pd.__version__ #print which version of pandas you're using"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the dataset. You can find more on reading CSV (Comma Separated Values) data as a Pandas dataframe [here](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>eccentricity</th>\n",
       "      <th>aspect-ratio</th>\n",
       "      <th>elongation</th>\n",
       "      <th>solidity</th>\n",
       "      <th>stochastic-convexity</th>\n",
       "      <th>isoperimetric-factor</th>\n",
       "      <th>maximal-indentation-depth</th>\n",
       "      <th>lobedness</th>\n",
       "      <th>average-intensity</th>\n",
       "      <th>average-contrast</th>\n",
       "      <th>smoothness</th>\n",
       "      <th>third-moment</th>\n",
       "      <th>uniformity</th>\n",
       "      <th>entropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0118</td>\n",
       "      <td>0.63010</td>\n",
       "      <td>0.57134</td>\n",
       "      <td>0.81053</td>\n",
       "      <td>0.16187</td>\n",
       "      <td>0.111150</td>\n",
       "      <td>2.248600</td>\n",
       "      <td>0.027309</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0.007839</td>\n",
       "      <td>0.002273</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.86000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>10.3770</td>\n",
       "      <td>0.90564</td>\n",
       "      <td>0.92135</td>\n",
       "      <td>0.99825</td>\n",
       "      <td>0.17941</td>\n",
       "      <td>0.016647</td>\n",
       "      <td>0.050433</td>\n",
       "      <td>0.020400</td>\n",
       "      <td>0.071662</td>\n",
       "      <td>0.005109</td>\n",
       "      <td>0.001266</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.71514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.19287</td>\n",
       "      <td>1.0551</td>\n",
       "      <td>0.25044</td>\n",
       "      <td>0.93641</td>\n",
       "      <td>0.99474</td>\n",
       "      <td>0.47284</td>\n",
       "      <td>0.019693</td>\n",
       "      <td>0.070581</td>\n",
       "      <td>0.055935</td>\n",
       "      <td>0.130300</td>\n",
       "      <td>0.016694</td>\n",
       "      <td>0.004583</td>\n",
       "      <td>0.000440</td>\n",
       "      <td>1.41110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.52212</td>\n",
       "      <td>1.1191</td>\n",
       "      <td>0.70988</td>\n",
       "      <td>0.50678</td>\n",
       "      <td>0.64912</td>\n",
       "      <td>0.14120</td>\n",
       "      <td>0.131920</td>\n",
       "      <td>3.167400</td>\n",
       "      <td>0.025478</td>\n",
       "      <td>0.085964</td>\n",
       "      <td>0.007336</td>\n",
       "      <td>0.002179</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.82809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.33254</td>\n",
       "      <td>1.1208</td>\n",
       "      <td>0.27473</td>\n",
       "      <td>0.93625</td>\n",
       "      <td>0.99474</td>\n",
       "      <td>0.49836</td>\n",
       "      <td>0.024394</td>\n",
       "      <td>0.108300</td>\n",
       "      <td>0.108090</td>\n",
       "      <td>0.168820</td>\n",
       "      <td>0.027709</td>\n",
       "      <td>0.005981</td>\n",
       "      <td>0.001234</td>\n",
       "      <td>2.48660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  eccentricity  aspect-ratio  elongation  solidity  \\\n",
       "0      1           NaN        1.0118     0.63010   0.57134   \n",
       "1      4       0.99512       10.3770     0.90564   0.92135   \n",
       "2      3       0.19287        1.0551     0.25044   0.93641   \n",
       "3      1       0.52212        1.1191     0.70988   0.50678   \n",
       "4      3       0.33254        1.1208     0.27473   0.93625   \n",
       "\n",
       "   stochastic-convexity  isoperimetric-factor  maximal-indentation-depth  \\\n",
       "0               0.81053               0.16187                   0.111150   \n",
       "1               0.99825               0.17941                   0.016647   \n",
       "2               0.99474               0.47284                   0.019693   \n",
       "3               0.64912               0.14120                   0.131920   \n",
       "4               0.99474               0.49836                   0.024394   \n",
       "\n",
       "   lobedness  average-intensity  average-contrast  smoothness  third-moment  \\\n",
       "0   2.248600           0.027309          0.088889    0.007839      0.002273   \n",
       "1   0.050433           0.020400          0.071662    0.005109      0.001266   \n",
       "2   0.070581           0.055935          0.130300    0.016694      0.004583   \n",
       "3   3.167400           0.025478          0.085964    0.007336      0.002179   \n",
       "4   0.108300           0.108090          0.168820    0.027709      0.005981   \n",
       "\n",
       "   uniformity  entropy  \n",
       "0    0.000175  0.86000  \n",
       "1    0.000170  0.71514  \n",
       "2    0.000440  1.41110  \n",
       "3    0.000149  0.82809  \n",
       "4    0.001234  2.48660  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaf_data = pd.read_csv(\"leaf.csv\")\n",
    "leaf_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. Eccentricity of the leaf is a measure of how much the shape of the leaf varies from a perfect circle. Unfortunately the dataset is missing values in the `eccentricity` column. How many missing values are there in this column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "# your code goes here\n",
    "print(leaf_data[\"eccentricity\"].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. Fill in these missing values with something reasonable. Show the head of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean = 0.5675259574468083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>eccentricity</th>\n",
       "      <th>aspect-ratio</th>\n",
       "      <th>elongation</th>\n",
       "      <th>solidity</th>\n",
       "      <th>stochastic-convexity</th>\n",
       "      <th>isoperimetric-factor</th>\n",
       "      <th>maximal-indentation-depth</th>\n",
       "      <th>lobedness</th>\n",
       "      <th>average-intensity</th>\n",
       "      <th>average-contrast</th>\n",
       "      <th>smoothness</th>\n",
       "      <th>third-moment</th>\n",
       "      <th>uniformity</th>\n",
       "      <th>entropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.567526</td>\n",
       "      <td>1.0118</td>\n",
       "      <td>0.63010</td>\n",
       "      <td>0.57134</td>\n",
       "      <td>0.81053</td>\n",
       "      <td>0.16187</td>\n",
       "      <td>0.111150</td>\n",
       "      <td>2.248600</td>\n",
       "      <td>0.027309</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0.007839</td>\n",
       "      <td>0.002273</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.86000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.995120</td>\n",
       "      <td>10.3770</td>\n",
       "      <td>0.90564</td>\n",
       "      <td>0.92135</td>\n",
       "      <td>0.99825</td>\n",
       "      <td>0.17941</td>\n",
       "      <td>0.016647</td>\n",
       "      <td>0.050433</td>\n",
       "      <td>0.020400</td>\n",
       "      <td>0.071662</td>\n",
       "      <td>0.005109</td>\n",
       "      <td>0.001266</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.71514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.192870</td>\n",
       "      <td>1.0551</td>\n",
       "      <td>0.25044</td>\n",
       "      <td>0.93641</td>\n",
       "      <td>0.99474</td>\n",
       "      <td>0.47284</td>\n",
       "      <td>0.019693</td>\n",
       "      <td>0.070581</td>\n",
       "      <td>0.055935</td>\n",
       "      <td>0.130300</td>\n",
       "      <td>0.016694</td>\n",
       "      <td>0.004583</td>\n",
       "      <td>0.000440</td>\n",
       "      <td>1.41110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.522120</td>\n",
       "      <td>1.1191</td>\n",
       "      <td>0.70988</td>\n",
       "      <td>0.50678</td>\n",
       "      <td>0.64912</td>\n",
       "      <td>0.14120</td>\n",
       "      <td>0.131920</td>\n",
       "      <td>3.167400</td>\n",
       "      <td>0.025478</td>\n",
       "      <td>0.085964</td>\n",
       "      <td>0.007336</td>\n",
       "      <td>0.002179</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.82809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.332540</td>\n",
       "      <td>1.1208</td>\n",
       "      <td>0.27473</td>\n",
       "      <td>0.93625</td>\n",
       "      <td>0.99474</td>\n",
       "      <td>0.49836</td>\n",
       "      <td>0.024394</td>\n",
       "      <td>0.108300</td>\n",
       "      <td>0.108090</td>\n",
       "      <td>0.168820</td>\n",
       "      <td>0.027709</td>\n",
       "      <td>0.005981</td>\n",
       "      <td>0.001234</td>\n",
       "      <td>2.48660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  eccentricity  aspect-ratio  elongation  solidity  \\\n",
       "0      1      0.567526        1.0118     0.63010   0.57134   \n",
       "1      4      0.995120       10.3770     0.90564   0.92135   \n",
       "2      3      0.192870        1.0551     0.25044   0.93641   \n",
       "3      1      0.522120        1.1191     0.70988   0.50678   \n",
       "4      3      0.332540        1.1208     0.27473   0.93625   \n",
       "\n",
       "   stochastic-convexity  isoperimetric-factor  maximal-indentation-depth  \\\n",
       "0               0.81053               0.16187                   0.111150   \n",
       "1               0.99825               0.17941                   0.016647   \n",
       "2               0.99474               0.47284                   0.019693   \n",
       "3               0.64912               0.14120                   0.131920   \n",
       "4               0.99474               0.49836                   0.024394   \n",
       "\n",
       "   lobedness  average-intensity  average-contrast  smoothness  third-moment  \\\n",
       "0   2.248600           0.027309          0.088889    0.007839      0.002273   \n",
       "1   0.050433           0.020400          0.071662    0.005109      0.001266   \n",
       "2   0.070581           0.055935          0.130300    0.016694      0.004583   \n",
       "3   3.167400           0.025478          0.085964    0.007336      0.002179   \n",
       "4   0.108300           0.108090          0.168820    0.027709      0.005981   \n",
       "\n",
       "   uniformity  entropy  \n",
       "0    0.000175  0.86000  \n",
       "1    0.000170  0.71514  \n",
       "2    0.000440  1.41110  \n",
       "3    0.000149  0.82809  \n",
       "4    0.001234  2.48660  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code goes here\n",
    "mean = leaf_data[\"eccentricity\"].mean()\n",
    "print(\"mean =\", mean)\n",
    "leaf_data[\"eccentricity\"].fillna(mean, inplace=True)\n",
    "leaf_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3. Standardize the `eccentricity` column. Where `value_std = (value - mean(value)) / std(value)`. Display the head of the new data frame.\n",
    "\n",
    "NOTE: You will want to add standardized eccentricity as a new column, rather than overwriting the existing eccentricty values with the standardized values. If you replace the original eccentricy values with the standardized ones, then happen to run the below code cell more than once, you will end up standardizing already standardized values, resulting in garbage numbers in that column. By adding a new column for the standardized eccentricity values, if the code cell is run multiple times, it will always be standardizing the original values in the eccentricty column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. Create a scatter plot between `smoothness` and standardized `eccentricity`. Place `smoothness` on the X axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5. Now plot the same scatter plot as Q4 but give a different color to each `class` label. What can you infer from this plot? (Provide a short answer in the form of comments.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6. Calculate the correlation coefficient between the standardized `eccentricity` and the `smoothness` column. What does this number tell us? (Provide a short answer in the form of comments.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7. Create a plot to determine if there are any outliers in the `average-contrast` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Adult Census Dataset\n",
    "\n",
    "For this task we'll be using the 1994 Adult Census Income data (`adult.csv`) collected by Ronny Kohavi and Barry Becker. This is a reasonably clean dataset with both categorical and integer attributes. The dataset consists of `32.5K` rows with 14 attributes.\n",
    "\n",
    "#### Attributes\n",
    "\n",
    "You can find a detailed description of the dataset [here](http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names).\n",
    "\n",
    "| Attribute Name \t\t| Type \t\t\t\t|\n",
    "| --------------------- | ----------------- |\n",
    "| age\t\t\t\t\t| continuous\t\t|\n",
    "| workclass\t\t\t\t| categorical\t\t|\n",
    "| fnlwgt\t\t\t\t| continuous\t\t|\n",
    "| education \t\t\t| categorical\t\t|\n",
    "| education-num\t\t\t| categorical\t\t|\n",
    "| marital-status\t\t| categorical\t\t|\n",
    "| occupation\t\t\t| categorical\t\t|\n",
    "| relationship\t\t\t| categorical\t\t|\n",
    "| race\t\t\t\t\t| categorical\t\t|\n",
    "| sex\t\t\t\t\t| categorical\t\t|\n",
    "| capital-gain\t\t\t| continuous\t\t|\n",
    "| capital-loss\t\t\t| continuous\t\t|\n",
    "| hours-per-week\t\t| continuous\t\t|\n",
    "| native-country\t\t| categorical\t\t|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the data. You can find more on reading CSV (Comma Separated Value) data as a Pandas dataframe [here](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>High-school</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt    education  education-num  \\\n",
       "0   39         State-gov   77516    Bachelors             13   \n",
       "1   50  Self-emp-not-inc   83311    Bachelors             13   \n",
       "2   38           Private  215646      HS-grad              9   \n",
       "3   53           Private  234721  High-school              7   \n",
       "4   28           Private  338409    Bachelors             13   \n",
       "\n",
       "       marital-status         occupation   relationship   race     sex  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week native-country  class  \n",
       "0          2174             0              40  United-States  <=50K  \n",
       "1             0             0              13  United-States  <=50K  \n",
       "2             0             0              40  United-States  <=50K  \n",
       "3             0             0              40  United-States  <=50K  \n",
       "4             0             0              40           Cuba  <=50K  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add skipinitialspace=True to skip spaces after delimiter (will be required later for the map function)\n",
    "adult_data = pd.read_csv(\"adult.csv\", skipinitialspace=True)\n",
    "# show the head of the data (first 5 values)\n",
    "adult_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                int64\n",
       "workclass         object\n",
       "fnlwgt             int64\n",
       "education         object\n",
       "education-num      int64\n",
       "marital-status    object\n",
       "occupation        object\n",
       "relationship      object\n",
       "race              object\n",
       "sex               object\n",
       "capital-gain       int64\n",
       "capital-loss       int64\n",
       "hours-per-week     int64\n",
       "native-country    object\n",
       "class             object\n",
       "dtype: object"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display data types of various columns in the dataframe\n",
    "adult_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8. Show the distribution of the dataset with respect to the `education` column. Choose a plot that is suitable to show this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q9.\n",
    "* Group the `adult_data` using the `marital-status` column. You may want to look at the `groupby()` method for dataframes [here](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html).\n",
    "* Display the mean, median and standard deviation statistics of `hours-per-week` column for each `marital-status` column.\n",
    "* As a comment, note which marital status category has the maximum average work hours per week? Which has the most variability in work hours per week? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please don't change this cell!!\n",
    "continent_dict = {\n",
    "    'Cambodia' : 'Asia',\n",
    "    'Canada' : 'North-America',\n",
    "    'China' : 'Asia',\n",
    "    'Columbia' : 'South-America',\n",
    "    'Cuba' : 'North-America',\n",
    "    'Dominican-Republic' : 'North-America',\n",
    "    'Ecuador' : 'South-America',\n",
    "    'El-Salvador' : 'North-America',\n",
    "    'England' : 'Europe',\n",
    "    'France' : 'Europe',\n",
    "    'Germany' : 'Europe',\n",
    "    'Greece' : 'Europe',\n",
    "    'Guatemala' : 'North-America',\n",
    "    'Haiti' : 'North-America',\n",
    "    'Holand-Netherlands' : 'Europe',\n",
    "    'Honduras' : 'North-America',\n",
    "    'Hong' : 'Asia',\n",
    "    'Hungary' : 'Europe',\n",
    "    'India' : 'Asia',\n",
    "    'Iran' : 'Asia',\n",
    "    'Ireland' : 'Europe',\n",
    "    'Italy' : 'Europe',\n",
    "    'Jamaica' : 'North-America',\n",
    "    'Japan' : 'Asia',\n",
    "    'Laos' : 'Asia',\n",
    "    'Mexico' : 'North-America',\n",
    "    'Nicaragua' : 'North-America',\n",
    "    'Outlying-US(Guam-USVI-etc)' : 'North-America',\n",
    "    'Peru' : 'South-America',\n",
    "    'Philippines' : 'Asia',\n",
    "    'Poland' : 'Europe',\n",
    "    'Portugal' : 'Europe',\n",
    "    'Puerto-Rico' : 'North-America',\n",
    "    'Scotland' : 'Europe',\n",
    "    'South' : 'Other',\n",
    "    'Taiwan' : 'Asia',\n",
    "    'Thailand' : 'Asia',\n",
    "    'Trinadad&Tobago' : 'South-America',\n",
    "    'United-States' : 'North-America',\n",
    "    'Vietnam' : 'Asia',\n",
    "    'Yugoslavia' : 'Europe',\n",
    "    '?' : 'Other'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q10. Using the dictionary provided above, create a new column called `continent` using the existing `native-country` column in the dataframe. You may want to look at the `map()` method for dataframes [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.map.html). Display the head of the new dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You will want to create a deep copy of the initial dataframe object\n",
    "# so that you can run this cell multiple times without errors.\n",
    "adult_data_copy = adult_data.copy()\n",
    "# add the new column to adult_data_copy\n",
    "# your code goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q11. Use matplotlib to plot a bar graph showing the average age of adults from each continent, and show the standard deviation on the same graph.\n",
    "\n",
    "An example bar plot with standard deviation bars:\n",
    "<img src=\"imgs/screen3.png\" width=400>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q12. To reduce the dimensionality of this dataset, which attribute or attributes would you eliminate? Explain why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Explain why here (as a comment):\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
